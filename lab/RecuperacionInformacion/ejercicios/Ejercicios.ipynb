{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "En este primer ejercicio procedemos a indexar la colección de documentos `train.docs`, dicha colección será tokenizada y se creará un índice BM25.\n",
    "\n",
    "Primero empezamos importando las dependencias necesarias:\n"
   ],
   "id": "46ba3c05b3288a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import bm25s\n",
    "import Stemmer"
   ],
   "id": "700ca52bd18e6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Estas librerías nos permiten:\n",
    "   - bm25s: Crear índices y buscar documentos usando BM25\n",
    "   - Stemmer: Realizar stemming de los términos\n",
    "\n",
    "Una vez importadas dichas librerías necesitamos carga el corpus para ello se define la siguiente función:"
   ],
   "id": "82139fb1532950f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def prepareCorpus():\n",
    "\n",
    "    # Cargamos el archivo train.docs, y lo separamos por el salto de línea\n",
    "    with open(\"../archivos/train.docs\",\"r\",encoding=\"utf-8\") as f:\n",
    "        corpus_content = f.read()\n",
    "        corpus_content = corpus_content.split(\"\\n\")\n",
    "\n",
    "    #Inicializamos unas listas vacías\n",
    "    corpus_plainText = list()\n",
    "    corpus_verbatim = list()\n",
    "\n",
    "    #Recorremos el corpus_content y lo dividimos en tres partes, el id, el título y el texto\n",
    "    for valor in corpus_content:\n",
    "        partes = valor.split(\"\\t\")\n",
    "        valor = partes[1].lower()\n",
    "        document = {\"id\": partes[0], \"title\":partes[0].lower(),\"text\": valor}\n",
    "        corpus_verbatim.append(document)\n",
    "        corpus_plainText.append(valor)\n",
    "\n",
    "    #Inicializamos el stemmer\n",
    "    stemmer = Stemmer.Stemmer(\"english\")\n",
    "\n",
    "    #Tokenizamos el corpus\n",
    "    corpus_tokenized = bm25s.tokenize(corpus_plainText, stopwords=\"en\", stemmer=stemmer, show_progress=True)\n",
    "\n",
    "    #Creamos el índice BM25 y lo guardamos en un archivo\n",
    "    retriever = createAndSaveRetriever(corpus_verbatim, corpus_tokenized)\n"
   ],
   "id": "d4b66eeedc3cdb95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "La función anterior lee el archivo `train.docs` y lo divide en tres partes, la primera parte es el id<sup>1</sup> del documento, la segunda es el título del documento y la tercera parte es el texto del documento. Luego se tokeniza el texto del documento y se guarda en un índice BM25.\n",
    "\n",
    "Este método llama a la función `createAndSaveRetriever()` que se encarga de crear el índice BM25 y guardarlo en un archivo.\n",
    "\n",
    "<sup>1</sup> El id es el mismo valor que el título presente en `train.docs`\n",
    "\n",
    "---\n",
    "La función `createAndSaveRetriever()` realiza lo siguiente:\n",
    "\n",
    "1. Crea un retriever BM25 con el corpus verbatim y los métodos de cálculo de BM25 y de idf.\n",
    "2. Indexa el corpus tokenizado.\n",
    "3. Guarda el retriever en un archivo, para posteriormente ser recuperado"
   ],
   "id": "533dd3fbbcaa8acf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def createAndSaveRetriever(corpus_verbatim, corpus_tokenized,method=\"lucene\",idf_method=\"lucene\"):\n",
    "\n",
    "    #Creacion del retriever\n",
    "    retriever = bm25s.BM25(corpus=corpus_verbatim, method=method, idf_method=idf_method)\n",
    "    #Indexado de la colección de documentos tokenizados\n",
    "    retriever.index(corpus_tokenized, show_progress=True)\n",
    "\n",
    "    #Guardado del retriever en un archivo\n",
    "    retriever.save(\"../archivos/NFcorpus\",corpus=corpus_verbatim)\n",
    "\n",
    "    return retriever"
   ],
   "id": "3c9b2018563805bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "En este documento también hay presente una función para poder cargar el retriever de un archivo, dicha función es `openRetriever()`:"
   ],
   "id": "e07e79b62feebdfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def openRetriever():\n",
    "    retriever = bm25s.BM25.load(\"../archivos/NFcorpus\",load_corpus=True)\n",
    "    return retriever"
   ],
   "id": "1f0948e68184517e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "En este segundo ejercicio se procede a cargar las queries y procesarlas con diferentes modelos de búsqueda para el retriever, y realizando dichas consultas con la combinación del steamer y stopwords<sup>1</sup>,para posteriormente poder calcular la precisión de las consultas y guardarlas en un archivo.\n",
    "\n",
    "<sup>1</sup>Se harán combinaciones de steamer y stopwords para poder comparar los resultados, dichas combinaciones son y para cada modelo de retriever: stopword-steaming, stopword-none-steaming, none-stopword-steaming, none-stopword-none-steaming."
   ],
   "id": "8f5fac819fd71c1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Primero empezaremos cargando y preparando el corpus, para ello se utilizará la función `prepareCorpus()` y `createRetriever()` usadas en el ejercicio anterior y presentes en el archivo python del ejercicio 2. También se usará la función de `tokenizado()`, para poder tokenizar el corpus y las consultas según diferentes configuraciones",
   "id": "3b2a82a30ed823b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def tokenizado(texto, stemmer, stopwords):\n",
    "    # Tokenizamos el corpus\n",
    "    corpus_tokenized = bm25s.tokenize(texto, stopwords=stopwords, stemmer=stemmer, show_progress=True)\n",
    "\n",
    "    return corpus_tokenized"
   ],
   "id": "56c1a2f3c8a5709c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tabla de resultados\n",
    "#### Macro promedios\n",
    "\n",
    "|  Modelo   | Steamer | Stopwords | Precision | Recall |    F1     |\n",
    "|:---------:|:-------:|:---------:|:---------:|:------:|:---------:|\n",
    "| Robertson |   No    |    No     |   0.064   | 0.261  | __0.101__ |\n",
    "| Robertson |   No    |    Si     |   0.066   | 0.265  | __0.103__ |\n",
    "| Robertson |   Si    |    No     |   0.067   | 0.273  | __0.105__ |\n",
    "| Robertson |   Si    |    Si     |   0.069   | 0.279  | __0.106__ |\n",
    "|   Atire   |   No    |    No     |   0.064   | 0.261  |  __0.1__  |\n",
    "|   Atire   |   No    |    Si     |   0.066   | 0.265  | __0.102__ |\n",
    "|   Atire   |   Si    |    No     |   0.067   | 0.273  | __0.104__ |\n",
    "|   Atire   |   Si    |    Si     |   0.069   | 0.278  | __0.107__ |\n",
    "|   Bm25l   |   No    |    No     |   0.064   | 0.263  | __0.101__ |\n",
    "|   Bm25l   |   No    |    Si     |   0.066   | 0.266  | __0.102__ |\n",
    "|   Bm25l   |   Si    |    No     |   0.068   | 0.275  | __0.105__ |\n",
    "|   Bm25l   |   Si    |    Si     |   0.069   | 0.279  | __0.106__ |\n",
    "|   Bm25+   |   No    |    No     |   0.064   | 0.261  |  __0.1__  |\n",
    "|   Bm25+   |   No    |    Si     |   0.066   | 0.265  | __0.102__ |\n",
    "|   Bm25+   |   Si    |    No     |   0.067   | 0.273  | __0.104__ |\n",
    "|   Bm25+   |   Si    |    Si     |   0.069   | 0.278  | __0.107__ |\n",
    "|  Lucene   |   No    |    No     |   0.064   | 0.261  |  __0.1__  |\n",
    "|  Lucene   |   No    |    Si     |   0.066   | 0.265  | __0.102__ |\n",
    "|  Lucene   |   Si    |    No     |   0.067   | 0.273  | __0.104__ |\n",
    "|  Lucene   |   Si    |    Si     |   0.069   | 0.278  | __0.107__ |\n",
    "\n",
    "#### Micro promedios\n",
    "\n",
    "|  Modelo   | Steamer | Stopwords | Precision | Recall |    F1     |\n",
    "|:---------:|:-------:|:---------:|:---------:|:------:|:---------:|\n",
    "| Robertson |   No    |    No     |   0.064   | 0.196  | __0.097__ |\n",
    "| Robertson |   No    |    Si     |   0.066   |  0.2   | __0.099__ |\n",
    "| Robertson |   Si    |    No     |   0.067   | 0.205  | __0.101__ |\n",
    "| Robertson |   Si    |    Si     |   0.069   |  0.21  | __0.104__ |\n",
    "|   Atire   |   No    |    No     |   0.064   | 0.196  | __0.097__ |\n",
    "|   Atire   |   No    |    Si     |   0.066   |  0.2   | __0.099__ |\n",
    "|   Atire   |   Si    |    No     |   0.067   | 0.205  | __0.101__ |\n",
    "|   Atire   |   Si    |    Si     |   0.069   |  0.21  | __0.104__ |\n",
    "|   Bm25l   |   No    |    No     |   0.064   | 0.197  | __0.097__ |\n",
    "|   Bm25l   |   No    |    Si     |   0.066   |  0.2   | __0.099__ |\n",
    "|   Bm25l   |   Si    |    No     |   0.068   | 0.206  | __0.102__ |\n",
    "|   Bm25l   |   Si    |    Si     |   0.069   |  0.21  | __0.104__ |\n",
    "|   Bm25+   |   No    |    No     |   0.064   | 0.196  | __0.097__ |\n",
    "|   Bm25+   |   No    |    Si     |   0.066   |  0.2   | __0.099__ |\n",
    "|   Bm25+   |   Si    |    No     |   0.067   | 0.205  | __0.101__ |\n",
    "|   Bm25+   |   Si    |    Si     |   0.069   |  0.21  | __0.104__ |\n",
    "|  Lucene   |   No    |    No     |   0.064   | 0.196  | __0.097__ |\n",
    "|  Lucene   |   No    |    Si     |   0.066   |  0.2   | __0.099__ |\n",
    "|  Lucene   |   Si    |    No     |   0.067   | 0.205  | __0.101__ |\n",
    "|  Lucene   |   Si    |    Si     |   0.069   |  0.21  | __0.104__ |\n",
    "\n",
    "Gracias a los datos obtenidos podemos concluir lo siguiente:\n",
    "\n",
    "- Macro promedios -> se consigue un valor F1 de 0.107\n",
    "    - Atire con steamer y stopwords\n",
    "    - Lucene con steamer y stopwords\n",
    "    - Bm25+ con steamer y stopwords\n",
    "\n",
    "- Micro promedios -> se consigue un valor F1 de 0.104\n",
    "    - Atire con steamer y stopwords\n",
    "    - Bm25l con steamer y stopwords\n",
    "    - Robertson con steamer y stopwords\n",
    "    - Bm25+ con steamer y stopwords\n",
    "    - Lucene con steamer y stopwords\n",
    "\n",
    "Podemos concluir que tanto Atire, como Lucene y Bm25+, con configuración stemmer y stopwords, son buenos modelos, ambos tienen mismos valores de precision, recall y f1, y en términos de micro promedio, todos los modelos consiguen un f1 de 0.104\n",
    "\n",
    "Debido a que hay varios modelos con el mismo f1, y en este caso de uso, elegiré el modelo Lucenen para el resto de ejercicios de la práctica\n",
    "\n",
    "---"
   ],
   "id": "7ee1cb264cfa5a06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ejercicio 3\n",
    "\n",
    "En este ejercicio se preparará un script para la realización bucle de expansión de consultas para el próximo ejercicio.\n",
    "\n",
    "* Primero empezaremos ejecutando la consulta (al igual que se hace en ejercicios anteriores) y obteniendo las frecuencias de palabras de los documentos obtenidos\n"
   ],
   "id": "9d18c0c133b44469"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import Counter #Se requiere de esta libreria para el correcto funcionamiento\n",
    "def frequency(corpus_tokenized):\n",
    "\n",
    "    tmp = dict()\n",
    "\n",
    "    for document in corpus_tokenized[0]:\n",
    "        freqs = dict(Counter(document))\n",
    "        for token, freq in freqs.items():\n",
    "            try:\n",
    "                tmp[token] += freq\n",
    "            except:\n",
    "                tmp[token] = freq\n",
    "\n",
    "    inverted_vocab = {corpus_tokenized[1][key]: key for key in corpus_tokenized[1].keys()}\n",
    "\n",
    "    total_freqs = dict()\n",
    "\n",
    "    for key, freq in dict(tmp).items():\n",
    "        term = inverted_vocab[key]\n",
    "        total_freqs[term] = freq\n",
    "\n",
    "\n",
    "    return total_freqs"
   ],
   "id": "7950f90f49e57d53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* El siguiente paso es obtener las frecuencias de todos los documentos menos los obtenidos por la consulta, que lo haremos con la función anterior dando como parámetro el corpus tokenizado (para dicha tokenización se usara la función `tokenizado()`), ya que esta función de frecuencia nos la da el resultado para toda la colección es necesario hacer la resta de conjuntos",
   "id": "c487bd64c4971bf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def resta(dic1, dic2):\n",
    "    result = dict()\n",
    "    for key in dic1.keys():\n",
    "        result[key] = dic1[key] - dic2.get(key, 0)\n",
    "    return result"
   ],
   "id": "29aa05ce3ca6a43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Una vez obtenido esto, calculamos el LLR (Log Likelihood Ratio) para cada término",
   "id": "55011e67b781e984"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "\n",
    "def x_log_x(x):\n",
    "    return 0.0 if x == 0 else x * math.log(x)\n",
    "\n",
    "def entropy(*elements):\n",
    "    total = sum(elements)\n",
    "    result = sum(x_log_x(element) for element in elements)\n",
    "    return x_log_x(total) - result\n",
    "\n",
    "def log_likelihood_ratio(k11, k12, k21, k22):\n",
    "    row_entropy = entropy(k11 + k12, k21 + k22)\n",
    "    column_entropy = entropy(k11 + k21, k12 + k22)\n",
    "    matrix_entropy = entropy(k11, k12, k21, k22)\n",
    "    if row_entropy + column_entropy < matrix_entropy:\n",
    "        return 0.0\n",
    "    return 2.0 * (row_entropy + column_entropy - matrix_entropy)\n",
    "\n",
    "def root_log_likelihood_ratio(k11, k12, k21, k22):\n",
    "    llr = log_likelihood_ratio(k11, k12, k21, k22)\n",
    "    sqrt_llr = math.sqrt(llr)\n",
    "    if (k11 / (k11 + k12)) < (k21 / (k21 + k22)):\n",
    "        sqrt_llr = -sqrt_llr\n",
    "    return sqrt_llr"
   ],
   "id": "a53b14a008326515"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* Por último, se ordenan los términos por su valor LLR y se seleccionan los m primeros términos, se declara como m, ya que será uno de los términos que se cambiara en el siguiente ejercicio\n",
    "\n"
   ],
   "id": "5a415de00d8adb39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def getBestWords(frequency, othersDocumentsFrequency, queryTokenize, m):\n",
    "    relevantsWords = sum(frequency.values())\n",
    "    othersWords = sum(othersDocumentsFrequency.values())\n",
    "\n",
    "    relevances = dict()\n",
    "\n",
    "    for word in frequency:\n",
    "        k11 = frequency[word]\n",
    "        k12 = relevantsWords - k11\n",
    "        k21 = othersDocumentsFrequency[word]\n",
    "        k22 = othersWords - k21\n",
    "\n",
    "        llr = root_log_likelihood_ratio(k11, k12, k21, k22)\n",
    "        relevances[word] = llr\n",
    "\n",
    "    relevances = dict(sorted(relevances.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    result = []\n",
    "    contador = 0\n",
    "\n",
    "    for key in relevances.keys():\n",
    "        if key not in queryTokenize:\n",
    "            result.append(key)\n",
    "            contador += 1\n",
    "        if contador >= m:\n",
    "            break\n",
    "\n",
    "    return result"
   ],
   "id": "ec03b53d53d76768"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Ahora solo nos quedaría añadir dichas palabras a la query principal y volver a ejecutar la consulta",
   "id": "508f18c4e35e625c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def updateQuery(query, bestWords):\n",
    "    for word in bestWords:\n",
    "        query += \" \"+word\n",
    "\n",
    "    return query"
   ],
   "id": "e843340460864186"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Con estas funciones tendríamos el script necesario para realizar la expansión de consultas, para facilitar las llamadas a dichas funciones decidí englobarlas en una sola función que reciba los parámetros necesarios,",
   "id": "da680b72f447213a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def ejecucion(n,m):\n",
    "\n",
    "    stemmer = Stemmer.Stemmer(\"english\")\n",
    "    stopwords = \"en\"\n",
    "\n",
    "    corpus_plain,corpus_verbatim = prepareCorpus()\n",
    "    corpus_tokenized = tokenizado(corpus_plain, stemmer, stopwords)\n",
    "\n",
    "    retriever = createRetriever(corpus_verbatim, corpus_tokenized, method=\"lucene\", idf_method=\"lucene\")\n",
    "    #retriever = openRetriever()\n",
    "\n",
    "    query = \"how contaminated are our children ?\"  # primera query\n",
    "    documents = processQueries(query, stemmer, stopwords, retriever, n)\n",
    "    documentsTokenized = tokenizado([doc[\"text\"] for doc in documents.documents[0]], stemmer, stopwords)\n",
    "\n",
    "    fre = frequency(documentsTokenized)\n",
    "\n",
    "    othersDocumentsFrequency = frequency(corpus_tokenized)\n",
    "\n",
    "    othersDocumentsFrequency = resta(othersDocumentsFrequency, fre)\n",
    "\n",
    "    bestWords = getBestWords(fre, othersDocumentsFrequency, tokenizado(query, stemmer, stopwords)[1], m)\n",
    "\n",
    "    updateQuerry = updateQuery(query, bestWords)\n",
    "\n",
    "    result = processQueries(updateQuerry, stemmer, stopwords, retriever, 100)"
   ],
   "id": "4bf9651f6469fd7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Bibliografía\n",
    "Enlaces consultado para la realización de los ejercicios:\n",
    "\n",
    "## Ejercicio 1\n",
    "- [Introduction to Lexical Search](https://colab.research.google.com/drive/1R4o4Mdt5mnByzFMjM9VihfOfbj3sNiVX?usp=sharing#scrollTo=OGGXn4zB1VIY)\n",
    "\n",
    "## Ejercicio 2\n",
    "\n",
    "- [Introduction to Lexical Search](https://colab.research.google.com/drive/1R4o4Mdt5mnByzFMjM9VihfOfbj3sNiVX?usp=sharing#scrollTo=OGGXn4zB1VIY)\n",
    "- [Lexical Search and Performance Evaluation](https://colab.research.google.com/drive/1V3QvmZdKO6I3NOF_8_3r4oa9DQklsdWK?usp=sharing)"
   ],
   "id": "105654e696a0e118"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "43d533eada7e50b0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
